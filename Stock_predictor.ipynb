{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personalized Stock Prediction App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might need updata yfinance to the latest to scrape the data successfully\n",
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevent packages\n",
    "\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data through API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the stock ticker and pull the historical data from a start date\n",
    "ticker=yf.Ticker('AAPL')\n",
    "start=dt.datetime(2011, 1, 1)\n",
    "end=dt.datetime.now()\n",
    "\n",
    "data=ticker.history(start=start, end=end, interval=\"1d\")\n",
    "print('The shape of the data is ', data.shape)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the daily closing price and normalize the data to (0,1)\n",
    "\n",
    "data_close=data.Close.values.reshape(-1,1)\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data=scaler.fit_transform(data_close)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the historical data\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.title('History Price of Apple')\n",
    "plt.plot(data.Close)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price $')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for Different Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_test_split_lstm(data, prediction_days, train_size=0.9):\n",
    "    \n",
    "    '''Split train and test data for RNN model\n",
    "    \n",
    "    Split train and test data according to the ratio in time order\n",
    "    \n",
    "    Args:\n",
    "        data is the preprocessed historical data\n",
    "        prediction_days is the number of historical data to use as input\n",
    "        train_size is the ratio of training set\n",
    "        \n",
    "    Returns:\n",
    "        input and label for training set and test set\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    n_train=int(len(data)*train_size)\n",
    "    x_train, y_train, x_test, y_test=[], [], [], []\n",
    "    \n",
    "    for i in range(prediction_days, n_train):\n",
    "        x_train.append(data[i-prediction_days:i, 0])\n",
    "        y_train.append(data[i, 0])\n",
    "    \n",
    "    for j in range(n_train, len(data)):\n",
    "        x_test.append(data[j-prediction_days:j, 0])\n",
    "        y_test.append(data[j, 0])\n",
    "    \n",
    "    x_train, y_train=np.array(x_train), np.array(y_train)\n",
    "    x_test, y_test=np.array(x_test), np.array(y_test)\n",
    "    x_train=np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test=np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split for RNN model\n",
    "\n",
    "prediction_days=60 # number of days used as input\n",
    "\n",
    "x_train, y_train, x_test, y_test=train_test_split_lstm(scaled_data, prediction_days)\n",
    "\n",
    "print('x_train has {} samples, x_test has {} samples'.format(x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split for regression model\n",
    "\n",
    "# number of historical data as input\n",
    "num_days=252\n",
    "# predict the stock price of future days\n",
    "future_days=1\n",
    "# get historical data\n",
    "data_reg=data_close[-num_days:]\n",
    "X=data_reg[:-future_days]\n",
    "y=data_reg[future_days:]\n",
    "\n",
    "# train test split and future data, set shuffle to false\n",
    "x_train1, x_test1, y_train1, y_test1=train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "x_future=X[-future_days:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model\n",
    "\n",
    "Build regression model using the data from the previous year from now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTree, LinearRegression, SVM model\n",
    "dt=DecisionTreeRegressor().fit(x_train1, y_train1)\n",
    "lr=LinearRegression().fit(x_train1, y_train1)\n",
    "svm=SVR(kernel='poly').fit(x_train1, y_train1.ravel())\n",
    "\n",
    "# evaluate the performance of the model on training set\n",
    "print('For training set: ')\n",
    "print('Linear      : mean square error is {}, r2_score is {}'.format(mean_squared_error(y_train1, lr.predict(x_train1)),\\\n",
    "                                                                     r2_score(y_train1, lr.predict(x_train1))))\n",
    "print('DecisionTree: mean square error is {}, r2_score is {}'.format(mean_squared_error(y_train1, dt.predict(x_train1)),\\\n",
    "                                                                     r2_score(y_train1, dt.predict(x_train1))))\n",
    "print('SVM         : mean square error is {}, r2_score is {}'.format(mean_squared_error(y_train1, svm.predict(x_train1)),\\\n",
    "                                                                     r2_score(y_train1, svm.predict(x_train1))))\n",
    "\n",
    "# make predictions on the testset\n",
    "dt_pred=dt.predict(x_test1)\n",
    "lr_pred=lr.predict(x_test1)\n",
    "svm_pred=svm.predict(x_test1)\n",
    "\n",
    "# evaluate the performance of the model on test set\n",
    "print('For test set: ')\n",
    "print('Linear      : mean square error is {}, r2_score is {}'.format(mean_squared_error(y_test1, lr_pred),\\\n",
    "                                                                     r2_score(y_test1, lr_pred)))\n",
    "print('DecisionTree: mean square error is {}, r2_score is {}'.format(mean_squared_error(y_test1, dt_pred),\\\n",
    "                                                                     r2_score(y_test1, dt_pred)))\n",
    "print('SVM         : mean square error is {}, r2_score is {}'.format(mean_squared_error(y_test1, svm_pred),\\\n",
    "                                                                     r2_score(y_test1, svm_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display the test prediction (recent stock price)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_future=data[-len(x_test1):]\n",
    "data_future['dt prediction']=dt_pred\n",
    "data_future['lr prediction']=lr_pred\n",
    "data_future['svm prediction']=svm_pred\n",
    "data_future=data_future[['Close', 'dt prediction', 'lr prediction', 'svm prediction']]\n",
    "data_future.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Regression Model')\n",
    "plt.plot(data.Close[-num_days:])\n",
    "plt.plot(data_future['dt prediction'])\n",
    "plt.plot(data_future['lr prediction'])\n",
    "plt.plot(data_future['svm prediction'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price $')\n",
    "plt.legend(['Actual Price', 'DecisionTree Prediction', 'Linear Prediction', 'SVM Prediction'])\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Recent 2 months')\n",
    "plt.plot(data.Close[-len(y_test1):])\n",
    "plt.plot(data_future['dt prediction'])\n",
    "plt.plot(data_future['lr prediction'])\n",
    "plt.plot(data_future['svm prediction'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price $')\n",
    "plt.legend(['Actual Price', 'DecisionTree Prediction', 'Linear Prediction', 'SVM Prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch to optimize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize parameters for DecisionTree Regression\n",
    "\n",
    "model=DecisionTreeRegressor()\n",
    "parameters={'max_depth': (None, 2, 3, 5, 8), #8\n",
    "            'criterion': ('mse', 'mae'),     #mse\n",
    "            'splitter': ('best', 'random')   #random\n",
    "           }\n",
    "\n",
    "cv_dt=GridSearchCV(model, param_grid=parameters,verbose=3)\n",
    "cv_dt.fit(x_train1, y_train1)\n",
    "cv_dt_pred=cv_dt.predict(x_test1)\n",
    "\n",
    "print('The best parameter set: ', cv_dt.best_params_)\n",
    "print('Trainset: mean square error is {}, r2_score is {}'.format(mean_squared_error(y_train1, cv_dt.predict(x_train1)),\\\n",
    "                                                                     r2_score(y_train1, cv_dt.predict(x_train1))))\n",
    "print('Testset: mean square error is {}, r2_score is {}'.format(mean_squared_error(y_test1, cv_dt_pred),\\\n",
    "                                                                     r2_score(y_test1, cv_dt_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize parameters for SVM Regression\n",
    "model=SVR()\n",
    "print(model.get_params())\n",
    "parameters={'kernel': ('poly', 'rbf', 'sigmoid'),       #poly\n",
    "            'C': (0.0001, 0.001, 0.01, 0.1, 1.0)        #C=1.0 \n",
    "           }\n",
    "\n",
    "cv_svm=GridSearchCV(model, param_grid=parameters, verbose=3)\n",
    "cv_svm.fit(x_train1, y_train1.ravel())\n",
    "cv_svm_pred=cv_svm.predict(x_test1)\n",
    "\n",
    "print('The best parameter set: ', cv_svm.best_params_)\n",
    "print('Trainset: mean square error is {}, r2_score is {}'.format(mean_squared_error(y_train1, cv_svm.predict(x_train1)),\\\n",
    "                                                                     r2_score(y_train1, cv_svm.predict(x_train1))))\n",
    "print('Testset: mean square error is {}, r2_score is {}'.format(mean_squared_error(y_test1, cv_svm_pred),\\\n",
    "                                                                     r2_score(y_test1, cv_svm_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final prediction for the next day stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast the stock price for the next day\n",
    "\n",
    "x_next_day=data_reg[-future_days].reshape(-1,1)\n",
    "lr_next_day=lr.predict(x_next_day)\n",
    "dt_next_day=cv_dt.predict(x_next_day)\n",
    "svm_next_day=cv_svm.predict(x_next_day)\n",
    "print('Next day prediction by Linear model is ', lr_next_day)\n",
    "print('Next day prediction by DecisionTree model is ', dt_next_day)\n",
    "print('Next day prediction by SVM model is', svm_next_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rmse=np.sqrt(mean_squared_error(y_test1, lr_pred))\n",
    "dt_rmse=np.sqrt(mean_squared_error(y_test1, cv_dt_pred))\n",
    "svm_rmse=np.sqrt(mean_squared_error(y_test1, cv_svm_pred))\n",
    "average_price=np.mean(y_test1)\n",
    "lr_percent=np.round(lr_rmse/average_price*100.0, 2)\n",
    "dt_percent=np.round(dt_rmse/average_price*100.0, 2)\n",
    "svm_percent=np.round(svm_rmse/average_price*100.0, 2)\n",
    "print('Predicted value is within {}% of the actual value on average for Linear Regression.'.format(lr_percent))\n",
    "print('Predicted value is within {}% of the actual value on average for DecisionTree Regression.'.format(dt_percent))\n",
    "print('Predicted value is within {}% of the actual value on average for SVM Regression.'.format(svm_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model parameters\n",
    "\n",
    "lstm_size=64\n",
    "input_size=(x_train.shape[1], x_train.shape[2])\n",
    "dropout=0.2\n",
    "dense_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build LSTM model and train the model for 20 epochs\n",
    "\n",
    "def create_model(lstm_size=64, dropout=0.2, dense_size=10):\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(LSTM(units=lstm_size, return_sequences=True, input_shape=input_size))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(units=lstm_size, return_sequences=False))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units=dense_size))\n",
    "    model.add(Dense(units=1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model=create_model(lstm_size, dropout, dense_size)\n",
    "model.summary()\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)\n",
    "\n",
    "y_fit=model.predict(x_train)\n",
    "y_fit_price=scaler.inverse_transform(y_fit)\n",
    "y_train_price=scaler.inverse_transform(y_train.reshape(-1,1))\n",
    "y_test_price=scaler.inverse_transform(y_test.reshape(-1,1))\n",
    "y_pred_price=scaler.inverse_transform(y_pred)\n",
    "\n",
    "print('For training set: ')\n",
    "print('mean square error is {}, r2_score is {}'.format(mean_squared_error(y_train_price, y_fit_price),\\\n",
    "                                                       r2_score(y_train_price, y_fit_price)))\n",
    "print('For test set: ')\n",
    "print('mean square error is {}, r2_score is {}'.format(mean_squared_error(y_test_price, y_pred_price),\\\n",
    "                                                       r2_score(y_test_price, y_pred_price)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final assessment\n",
    "lstm_rmse=np.sqrt(mean_squared_error(y_test_price, y_pred_price))\n",
    "average_price=np.mean(y_test_price)\n",
    "lstm_percent=np.round(lstm_rmse/average_price*100.0, 2)\n",
    "\n",
    "print('Predicted value is within {}% of the actual value on average for LSTM.'.format(lstm_percent))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This Cell below takes long time to run. Try reduce the number of variables in the parameters dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize parameters for LSTM model\n",
    "lstm=KerasRegressor(build_fn=create_model, epochs=20, batch_size=64, verbose=0)\n",
    "parameters = {'lstm_size': ([20, 32, 64]) , #64 (20, 32, 64)\n",
    "              'dropout': ([0.2, 0.3, 0.5]), #0.2 (0.2, 0.3, 0.5)\n",
    "              'dense_size': (50, 20, 10)} #10\n",
    "\n",
    "cv_lstm=GridSearchCV(lstm, parameters, verbose=3)\n",
    "cv_lstm.fit(x_train, y_train)\n",
    "cv_lstm_pred=cv_lstm.predict(x_test).reshape(-1,1)\n",
    "\n",
    "y_pred_price=scaler.inverse_transform(cv_lstm_pred)\n",
    "\n",
    "y_fit=cv_lstm.predict(x_train).reshape(-1,1)\n",
    "y_fit_price=scaler.inverse_transform(y_fit)\n",
    "y_train_price=scaler.inverse_transform(y_train.reshape(-1,1))\n",
    "y_test_price=scaler.inverse_transform(y_test.reshape(-1,1))\n",
    "\n",
    "\n",
    "print('The best parameter set: ', cv_lstm.best_params_)\n",
    "print('For training set: ')\n",
    "print('mean square error is {}, r2_score is {}'.format(mean_squared_error(y_train_price, y_fit_price),\\\n",
    "                                                       r2_score(y_train_price, y_fit_price)))\n",
    "print('For test set: ')\n",
    "print('mean square error is {}, r2_score is {}'.format(mean_squared_error(y_test_price, y_pred_price),\\\n",
    "                                                       r2_score(y_test_price, y_pred_price)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predicted price and actual price\n",
    "n_train=x_train.shape[0]+prediction_days\n",
    "train=data.iloc[:n_train, :]\n",
    "valid=data.iloc[n_train:, :]\n",
    "valid['Prediction']=y_pred_price\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.subplot(2,1,1)\n",
    "plt.title('LSTM model for Apple stock Prediction')\n",
    "plt.plot(train['Close'], color='blue')\n",
    "plt.plot(valid[['Close', 'Prediction']])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price $')\n",
    "plt.legend(['Train', 'Val', 'Prediction'])\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.title('Recent Stock Validation')\n",
    "plt.plot(valid[['Close', 'Prediction']])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price $')\n",
    "plt.legend([ 'Val', 'Prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot recent stock prediction and compare with actual price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models on the test set\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Apple Stock Predicted by Linear Regression')\n",
    "plt.plot(data.Close[-len(y_test1):])\n",
    "plt.plot(data_future['lr prediction'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price $')\n",
    "plt.legend(['Actual Price', 'Linear Prediction'])\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Apple Stock Predicted by DecisionTree')\n",
    "plt.plot(data.Close[-len(y_test1):])\n",
    "plt.plot(data_future['dt prediction'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price $')\n",
    "plt.legend(['Actual Price', 'DecisionTree Prediction'])\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('Apple Stock Predicted by SVM')\n",
    "plt.plot(data.Close[-len(y_test1):])\n",
    "plt.plot(data_future['svm prediction'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price $')\n",
    "plt.legend(['Actual Price', 'SVM Prediction'])\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(data.Close[-len(y_test1):])\n",
    "plt.plot(valid['Prediction'][-len(y_test1):])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price $')\n",
    "plt.legend(['Actual Price', 'LSTM Prediction'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM next day prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_day=[scaled_data[len(scaled_data)-prediction_days:,0]]\n",
    "next_day=np.array(next_day)\n",
    "next_day=np.reshape(next_day, (next_day.shape[0], next_day.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_next_day=model.predict(next_day)\n",
    "pred_next_day=scaler.inverse_transform(pred_next_day)\n",
    "print('The prediction for next day is ', pred_next_day[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series cross validation for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for cross validation\n",
    "\n",
    "def rolling_forecast(x_train, y_train, min_train_size=1500, horizon=200):\n",
    "    '''\n",
    "    Create k-fold cross validation\n",
    "    \n",
    "    Args:\n",
    "        x_train (numpy array): training data input\n",
    "        y_train (numpy array): training data output\n",
    "        min_train_size (int): min training data size\n",
    "        horizon (int)ï¼švalidation size of future data\n",
    "    \n",
    "    Returns:\n",
    "        yield a data generator\n",
    "    '''\n",
    "    for i in range(0, train.shape[0]-min_train_size-horizon, horizon):\n",
    "        split_x_train, split_y_train=x_train[:min_train_size+i, :, :], y_train[:min_train_size+i]\n",
    "        split_x_val, split_y_val=x_train[min_train_size+i:min_train_size+i+horizon , :, :], \\\n",
    "                                 y_train[min_train_size+i:min_train_size+i+horizon]\n",
    "        yield split_x_train, split_y_train, split_x_val, split_y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation\n",
    "\n",
    "cv=rolling_forecast(x_train, y_train)\n",
    "model_cv=create_model(lstm_size, dropout, dense_size)\n",
    "cv_mse, cv_percentage=[], []\n",
    "\n",
    "for cv_x_train, cv_y_train, cv_x_val, cv_y_val in cv:\n",
    "    model_cv.fit(cv_x_train, cv_y_train, epochs=20, batch_size=64, verbose=0)\n",
    "    preds=model_cv.predict(cv_x_val)\n",
    "    \n",
    "    y_val_price=scaler.inverse_transform(cv_y_val.reshape(-1,1))\n",
    "    y_pred_price=scaler.inverse_transform(preds.reshape(-1,1))\n",
    "    \n",
    "    mse=mean_squared_error(y_val_price, y_pred_price)\n",
    "    percentage=np.sqrt(mse)/np.mean(y_val_price)*100.0\n",
    "    print('mse is {}, prediction within {}%'.format(mse, percentage))\n",
    "    \n",
    "    cv_mse.append(mse)\n",
    "    cv_percentage.append(percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
